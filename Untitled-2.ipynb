{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 7.653\n",
      "[1,   200] loss: 5.041\n",
      "[1,   300] loss: 5.277\n",
      "[1,   400] loss: 4.582\n",
      "[1,   500] loss: 3.893\n",
      "[1,   600] loss: 2.600\n",
      "[1,   700] loss: 0.986\n",
      "[1,   800] loss: 0.360\n",
      "[1,   900] loss: 0.297\n",
      "[1,  1000] loss: 0.240\n",
      "[1,  1100] loss: 0.231\n",
      "[1,  1200] loss: 0.265\n",
      "[1,  1300] loss: 0.243\n",
      "[1,  1400] loss: 0.235\n",
      "[1,  1500] loss: 0.229\n",
      "[1,  1600] loss: 0.218\n",
      "[1,  1700] loss: 0.234\n",
      "[1,  1800] loss: 0.222\n",
      "[1,  1900] loss: 0.223\n",
      "[1,  2000] loss: 0.227\n",
      "[1,  2100] loss: 0.229\n",
      "[1,  2200] loss: 0.225\n",
      "[1,  2300] loss: 0.225\n",
      "[1,  2400] loss: 0.207\n",
      "[1,  2500] loss: 0.208\n",
      "[1,  2600] loss: 0.208\n",
      "[1,  2700] loss: 0.197\n",
      "[1,  2800] loss: 0.209\n",
      "[1,  2900] loss: 0.197\n",
      "[1,  3000] loss: 0.213\n",
      "[1,  3100] loss: 0.192\n",
      "[1,  3200] loss: 0.188\n",
      "[1,  3300] loss: 0.196\n",
      "[1,  3400] loss: 0.190\n",
      "[1,  3500] loss: 0.184\n",
      "[1,  3600] loss: 0.219\n",
      "[1,  3700] loss: 0.201\n",
      "[1,  3800] loss: 0.209\n",
      "[1,  3900] loss: 0.208\n",
      "[1,  4000] loss: 0.212\n",
      "[1,  4100] loss: 0.207\n",
      "[1,  4200] loss: 0.191\n",
      "[1,  4300] loss: 0.195\n",
      "[1,  4400] loss: 0.206\n",
      "[1,  4500] loss: 0.188\n",
      "[1,  4600] loss: 0.178\n",
      "[1,  4700] loss: 0.228\n",
      "[1,  4800] loss: 0.195\n",
      "[1,  4900] loss: 0.186\n",
      "[1,  5000] loss: 0.181\n",
      "[1,  5100] loss: 0.195\n",
      "[1,  5200] loss: 0.198\n",
      "[1,  5300] loss: 0.190\n",
      "[1,  5400] loss: 0.199\n",
      "[1,  5500] loss: 0.186\n",
      "[1,  5600] loss: 0.179\n",
      "[1,  5700] loss: 0.175\n",
      "[1,  5800] loss: 0.186\n",
      "[1,  5900] loss: 0.177\n",
      "[1,  6000] loss: 0.190\n",
      "[1,  6100] loss: 0.176\n",
      "[1,  6200] loss: 0.191\n",
      "[1,  6300] loss: 0.203\n",
      "[1,  6400] loss: 0.177\n",
      "[1,  6500] loss: 0.175\n",
      "[1,  6600] loss: 0.188\n",
      "[1,  6700] loss: 0.172\n",
      "[1,  6800] loss: 0.184\n",
      "[1,  6900] loss: 0.178\n",
      "[1,  7000] loss: 0.202\n",
      "[1,  7100] loss: 0.186\n",
      "[1,  7200] loss: 0.169\n",
      "[1,  7300] loss: 0.174\n",
      "[1,  7400] loss: 0.177\n",
      "[1,  7500] loss: 0.177\n",
      "[1,  7600] loss: 0.175\n",
      "[1,  7700] loss: 0.165\n",
      "[1,  7800] loss: 0.176\n",
      "[1,  7900] loss: 0.166\n",
      "[1,  8000] loss: 0.172\n",
      "[1,  8100] loss: 0.179\n",
      "[1,  8200] loss: 0.169\n",
      "[1,  8300] loss: 0.172\n",
      "[1,  8400] loss: 0.173\n",
      "[1,  8500] loss: 0.183\n",
      "[1,  8600] loss: 0.211\n",
      "[1,  8700] loss: 0.176\n",
      "[1,  8800] loss: 0.223\n",
      "[1,  8900] loss: 0.172\n",
      "[1,  9000] loss: 0.178\n",
      "[1,  9100] loss: 0.158\n",
      "[1,  9200] loss: 0.169\n",
      "[1,  9300] loss: 0.183\n",
      "[1,  9400] loss: 0.179\n",
      "[1,  9500] loss: 0.166\n",
      "[1,  9600] loss: 0.181\n",
      "[1,  9700] loss: 0.158\n",
      "[1,  9800] loss: 0.166\n",
      "[1,  9900] loss: 0.172\n",
      "[1, 10000] loss: 0.177\n",
      "[1, 10100] loss: 0.161\n",
      "[1, 10200] loss: 0.179\n",
      "[1, 10300] loss: 0.202\n",
      "[1, 10400] loss: 0.195\n",
      "[1, 10500] loss: 0.171\n",
      "[1, 10600] loss: 0.163\n",
      "[1, 10700] loss: 0.162\n",
      "[1, 10800] loss: 0.165\n",
      "[1, 10900] loss: 0.175\n",
      "[1, 11000] loss: 0.166\n",
      "[1, 11100] loss: 0.154\n",
      "[1, 11200] loss: 0.166\n",
      "[1, 11300] loss: 0.167\n",
      "[1, 11400] loss: 0.154\n",
      "[1, 11500] loss: 0.167\n",
      "[1, 11600] loss: 0.170\n",
      "[1, 11700] loss: 0.168\n",
      "[1, 11800] loss: 0.169\n",
      "[1, 11900] loss: 0.168\n",
      "[1, 12000] loss: 0.173\n",
      "[1, 12100] loss: 0.148\n",
      "[1, 12200] loss: 0.170\n",
      "[1, 12300] loss: 0.157\n",
      "[1, 12400] loss: 0.157\n",
      "[1, 12500] loss: 0.186\n",
      "[1, 12600] loss: 0.154\n",
      "Epoch 1 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9518    0.9980    0.9743   3055493\n",
      "         1.0     0.8349    0.1670    0.2783    185421\n",
      "\n",
      "    accuracy                         0.9505   3240914\n",
      "   macro avg     0.8934    0.5825    0.6263   3240914\n",
      "weighted avg     0.9451    0.9505    0.9345   3240914\n",
      "\n",
      "AUC: 0.7687\n",
      "[2,   100] loss: 0.169\n",
      "[2,   200] loss: 0.153\n",
      "[2,   300] loss: 0.154\n",
      "[2,   400] loss: 0.186\n",
      "[2,   500] loss: 0.156\n",
      "[2,   600] loss: 0.157\n",
      "[2,   700] loss: 0.167\n",
      "[2,   800] loss: 0.315\n",
      "[2,   900] loss: 0.163\n",
      "[2,  1000] loss: 0.159\n",
      "[2,  1100] loss: 0.175\n",
      "[2,  1200] loss: 0.153\n",
      "[2,  1300] loss: 0.189\n",
      "[2,  1400] loss: 0.163\n",
      "[2,  1500] loss: 0.162\n",
      "[2,  1600] loss: 0.162\n",
      "[2,  1700] loss: 0.139\n",
      "[2,  1800] loss: 0.210\n",
      "[2,  1900] loss: 0.166\n",
      "[2,  2000] loss: 0.151\n",
      "[2,  2100] loss: 0.156\n",
      "[2,  2200] loss: 0.171\n",
      "[2,  2300] loss: 0.166\n",
      "[2,  2400] loss: 0.154\n",
      "[2,  2500] loss: 0.154\n",
      "[2,  2600] loss: 0.154\n",
      "[2,  2700] loss: 0.169\n",
      "[2,  2800] loss: 0.148\n",
      "[2,  2900] loss: 0.160\n",
      "[2,  3000] loss: 0.154\n",
      "[2,  3100] loss: 0.164\n",
      "[2,  3200] loss: 0.163\n",
      "[2,  3300] loss: 0.163\n",
      "[2,  3400] loss: 0.172\n",
      "[2,  3500] loss: 0.158\n",
      "[2,  3600] loss: 0.146\n",
      "[2,  3700] loss: 0.164\n",
      "[2,  3800] loss: 0.168\n",
      "[2,  3900] loss: 0.156\n",
      "[2,  4000] loss: 0.161\n",
      "[2,  4100] loss: 0.151\n",
      "[2,  4200] loss: 0.147\n",
      "[2,  4300] loss: 0.166\n",
      "[2,  4400] loss: 0.162\n",
      "[2,  4500] loss: 0.152\n",
      "[2,  4600] loss: 0.181\n",
      "[2,  4700] loss: 0.152\n",
      "[2,  4800] loss: 0.155\n",
      "[2,  4900] loss: 0.154\n",
      "[2,  5000] loss: 0.293\n",
      "[2,  5100] loss: 0.184\n",
      "[2,  5200] loss: 0.139\n",
      "[2,  5300] loss: 0.143\n",
      "[2,  5400] loss: 0.152\n",
      "[2,  5500] loss: 0.156\n",
      "[2,  5600] loss: 0.169\n",
      "[2,  5700] loss: 0.142\n",
      "[2,  5800] loss: 0.162\n",
      "[2,  5900] loss: 0.151\n",
      "[2,  6000] loss: 0.150\n",
      "[2,  6100] loss: 0.152\n",
      "[2,  6200] loss: 0.159\n",
      "[2,  6300] loss: 0.160\n",
      "[2,  6400] loss: 0.138\n",
      "[2,  6500] loss: 0.172\n",
      "[2,  6600] loss: 0.140\n",
      "[2,  6700] loss: 0.145\n",
      "[2,  6800] loss: 0.143\n",
      "[2,  6900] loss: 0.171\n",
      "[2,  7000] loss: 0.136\n",
      "[2,  7100] loss: 0.148\n",
      "[2,  7200] loss: 0.136\n",
      "[2,  7300] loss: 0.146\n",
      "[2,  7400] loss: 0.150\n",
      "[2,  7500] loss: 0.150\n",
      "[2,  7600] loss: 0.154\n",
      "[2,  7700] loss: 0.149\n",
      "[2,  7800] loss: 0.154\n",
      "[2,  7900] loss: 0.142\n",
      "[2,  8000] loss: 0.150\n",
      "[2,  8100] loss: 0.152\n",
      "[2,  8200] loss: 0.136\n",
      "[2,  8300] loss: 0.135\n",
      "[2,  8400] loss: 0.161\n",
      "[2,  8500] loss: 0.143\n",
      "[2,  8600] loss: 0.142\n",
      "[2,  8700] loss: 0.146\n",
      "[2,  8800] loss: 0.170\n",
      "[2,  8900] loss: 0.145\n",
      "[2,  9000] loss: 0.133\n",
      "[2,  9100] loss: 0.137\n",
      "[2,  9200] loss: 0.142\n",
      "[2,  9300] loss: 0.151\n",
      "[2,  9400] loss: 0.148\n",
      "[2,  9500] loss: 0.139\n",
      "[2,  9600] loss: 0.179\n",
      "[2,  9700] loss: 0.145\n",
      "[2,  9800] loss: 0.162\n",
      "[2,  9900] loss: 0.165\n",
      "[2, 10000] loss: 0.150\n",
      "[2, 10100] loss: 0.141\n",
      "[2, 10200] loss: 0.140\n",
      "[2, 10300] loss: 0.139\n",
      "[2, 10400] loss: 0.150\n",
      "[2, 10500] loss: 0.140\n",
      "[2, 10600] loss: 0.141\n",
      "[2, 10700] loss: 0.136\n",
      "[2, 10800] loss: 0.143\n",
      "[2, 10900] loss: 0.143\n",
      "[2, 11000] loss: 0.139\n",
      "[2, 11100] loss: 0.145\n",
      "[2, 11200] loss: 0.154\n",
      "[2, 11300] loss: 0.152\n",
      "[2, 11400] loss: 0.145\n",
      "[2, 11500] loss: 0.146\n",
      "[2, 11600] loss: 0.134\n",
      "[2, 11700] loss: 0.142\n",
      "[2, 11800] loss: 0.150\n",
      "[2, 11900] loss: 0.147\n",
      "[2, 12000] loss: 0.145\n",
      "[2, 12100] loss: 0.132\n",
      "[2, 12200] loss: 0.148\n",
      "[2, 12300] loss: 0.150\n",
      "[2, 12400] loss: 0.138\n",
      "[2, 12500] loss: 0.152\n",
      "[2, 12600] loss: 0.140\n",
      "Epoch 2 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9610    0.9990    0.9796   3055493\n",
      "         1.0     0.9518    0.3312    0.4914    185421\n",
      "\n",
      "    accuracy                         0.9608   3240914\n",
      "   macro avg     0.9564    0.6651    0.7355   3240914\n",
      "weighted avg     0.9604    0.9608    0.9517   3240914\n",
      "\n",
      "AUC: 0.8646\n",
      "[3,   100] loss: 0.144\n",
      "[3,   200] loss: 0.146\n",
      "[3,   300] loss: 0.133\n",
      "[3,   400] loss: 0.138\n",
      "[3,   500] loss: 0.136\n",
      "[3,   600] loss: 0.160\n",
      "[3,   700] loss: 0.126\n",
      "[3,   800] loss: 0.137\n",
      "[3,   900] loss: 0.138\n",
      "[3,  1000] loss: 0.128\n",
      "[3,  1100] loss: 0.160\n",
      "[3,  1200] loss: 0.132\n",
      "[3,  1300] loss: 0.130\n",
      "[3,  1400] loss: 0.153\n",
      "[3,  1500] loss: 0.145\n",
      "[3,  1600] loss: 0.130\n",
      "[3,  1700] loss: 0.128\n",
      "[3,  1800] loss: 0.132\n",
      "[3,  1900] loss: 0.144\n",
      "[3,  2000] loss: 0.136\n",
      "[3,  2100] loss: 0.152\n",
      "[3,  2200] loss: 0.141\n",
      "[3,  2300] loss: 0.138\n",
      "[3,  2400] loss: 0.147\n",
      "[3,  2500] loss: 0.134\n",
      "[3,  2600] loss: 0.128\n",
      "[3,  2700] loss: 0.140\n",
      "[3,  2800] loss: 0.131\n",
      "[3,  2900] loss: 0.124\n",
      "[3,  3000] loss: 0.136\n",
      "[3,  3100] loss: 0.136\n",
      "[3,  3200] loss: 0.137\n",
      "[3,  3300] loss: 0.133\n",
      "[3,  3400] loss: 0.129\n",
      "[3,  3500] loss: 0.146\n",
      "[3,  3600] loss: 0.116\n",
      "[3,  3700] loss: 0.141\n",
      "[3,  3800] loss: 0.143\n",
      "[3,  3900] loss: 0.127\n",
      "[3,  4000] loss: 0.125\n",
      "[3,  4100] loss: 0.134\n",
      "[3,  4200] loss: 0.121\n",
      "[3,  4300] loss: 0.133\n",
      "[3,  4400] loss: 0.150\n",
      "[3,  4500] loss: 0.133\n",
      "[3,  4600] loss: 0.141\n",
      "[3,  4700] loss: 0.150\n",
      "[3,  4800] loss: 0.132\n",
      "[3,  4900] loss: 0.138\n",
      "[3,  5000] loss: 0.149\n",
      "[3,  5100] loss: 0.128\n",
      "[3,  5200] loss: 0.147\n",
      "[3,  5300] loss: 0.128\n",
      "[3,  5400] loss: 0.138\n",
      "[3,  5500] loss: 0.135\n",
      "[3,  5600] loss: 0.156\n",
      "[3,  5700] loss: 0.135\n",
      "[3,  5800] loss: 0.149\n",
      "[3,  5900] loss: 0.161\n",
      "[3,  6000] loss: 0.148\n",
      "[3,  6100] loss: 0.129\n",
      "[3,  6200] loss: 0.137\n",
      "[3,  6300] loss: 0.132\n",
      "[3,  6400] loss: 0.120\n",
      "[3,  6500] loss: 0.126\n",
      "[3,  6600] loss: 0.165\n",
      "[3,  6700] loss: 0.123\n",
      "[3,  6800] loss: 0.130\n",
      "[3,  6900] loss: 0.139\n",
      "[3,  7000] loss: 0.123\n",
      "[3,  7100] loss: 0.118\n",
      "[3,  7200] loss: 0.134\n",
      "[3,  7300] loss: 0.127\n",
      "[3,  7400] loss: 0.126\n",
      "[3,  7500] loss: 0.127\n",
      "[3,  7600] loss: 0.137\n",
      "[3,  7700] loss: 0.122\n",
      "[3,  7800] loss: 0.122\n",
      "[3,  7900] loss: 0.121\n",
      "[3,  8000] loss: 0.135\n",
      "[3,  8100] loss: 0.123\n",
      "[3,  8200] loss: 0.137\n",
      "[3,  8300] loss: 0.122\n",
      "[3,  8400] loss: 0.134\n",
      "[3,  8500] loss: 0.144\n",
      "[3,  8600] loss: 0.130\n",
      "[3,  8700] loss: 0.130\n",
      "[3,  8800] loss: 0.117\n",
      "[3,  8900] loss: 0.120\n",
      "[3,  9000] loss: 0.126\n",
      "[3,  9100] loss: 0.126\n",
      "[3,  9200] loss: 0.131\n",
      "[3,  9300] loss: 0.126\n",
      "[3,  9400] loss: 0.125\n",
      "[3,  9500] loss: 0.137\n",
      "[3,  9600] loss: 0.146\n",
      "[3,  9700] loss: 0.157\n",
      "[3,  9800] loss: 0.143\n",
      "[3,  9900] loss: 0.144\n",
      "[3, 10000] loss: 0.107\n",
      "[3, 10100] loss: 0.117\n",
      "[3, 10200] loss: 0.114\n",
      "[3, 10300] loss: 0.121\n",
      "[3, 10400] loss: 0.113\n",
      "[3, 10500] loss: 0.147\n",
      "[3, 10600] loss: 0.123\n",
      "[3, 10700] loss: 0.130\n",
      "[3, 10800] loss: 0.117\n",
      "[3, 10900] loss: 0.123\n",
      "[3, 11000] loss: 0.120\n",
      "[3, 11100] loss: 0.114\n",
      "[3, 11200] loss: 0.108\n",
      "[3, 11300] loss: 0.140\n",
      "[3, 11400] loss: 0.137\n",
      "[3, 11500] loss: 0.137\n",
      "[3, 11600] loss: 0.130\n",
      "[3, 11700] loss: 0.121\n",
      "[3, 11800] loss: 0.110\n",
      "[3, 11900] loss: 0.127\n",
      "[3, 12000] loss: 0.153\n",
      "[3, 12100] loss: 0.122\n",
      "[3, 12200] loss: 0.130\n",
      "[3, 12300] loss: 0.119\n",
      "[3, 12400] loss: 0.107\n",
      "[3, 12500] loss: 0.122\n",
      "[3, 12600] loss: 0.130\n",
      "Epoch 3 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9653    0.9993    0.9820   3055493\n",
      "         1.0     0.9724    0.4079    0.5747    185421\n",
      "\n",
      "    accuracy                         0.9655   3240914\n",
      "   macro avg     0.9689    0.7036    0.7784   3240914\n",
      "weighted avg     0.9657    0.9655    0.9587   3240914\n",
      "\n",
      "AUC: 0.8973\n",
      "[4,   100] loss: 0.151\n",
      "[4,   200] loss: 0.141\n",
      "[4,   300] loss: 0.125\n",
      "[4,   400] loss: 0.113\n",
      "[4,   500] loss: 0.118\n",
      "[4,   600] loss: 0.135\n",
      "[4,   700] loss: 0.115\n",
      "[4,   800] loss: 0.121\n",
      "[4,   900] loss: 0.108\n",
      "[4,  1000] loss: 0.108\n",
      "[4,  1100] loss: 0.135\n",
      "[4,  1200] loss: 0.118\n",
      "[4,  1300] loss: 0.122\n",
      "[4,  1400] loss: 0.137\n",
      "[4,  1500] loss: 0.125\n",
      "[4,  1600] loss: 0.110\n",
      "[4,  1700] loss: 0.122\n",
      "[4,  1800] loss: 0.113\n",
      "[4,  1900] loss: 0.110\n",
      "[4,  2000] loss: 0.111\n",
      "[4,  2100] loss: 0.120\n",
      "[4,  2200] loss: 0.126\n",
      "[4,  2300] loss: 0.147\n",
      "[4,  2400] loss: 0.128\n",
      "[4,  2500] loss: 0.118\n",
      "[4,  2600] loss: 0.115\n",
      "[4,  2700] loss: 0.112\n",
      "[4,  2800] loss: 0.120\n",
      "[4,  2900] loss: 0.113\n",
      "[4,  3000] loss: 0.117\n",
      "[4,  3100] loss: 0.120\n",
      "[4,  3200] loss: 0.148\n",
      "[4,  3300] loss: 0.126\n",
      "[4,  3400] loss: 0.119\n",
      "[4,  3500] loss: 0.117\n",
      "[4,  3600] loss: 0.106\n",
      "[4,  3700] loss: 0.122\n",
      "[4,  3800] loss: 0.123\n",
      "[4,  3900] loss: 0.113\n",
      "[4,  4000] loss: 0.144\n",
      "[4,  4100] loss: 0.115\n",
      "[4,  4200] loss: 0.113\n",
      "[4,  4300] loss: 0.113\n",
      "[4,  4400] loss: 0.121\n",
      "[4,  4500] loss: 0.123\n",
      "[4,  4600] loss: 0.125\n",
      "[4,  4700] loss: 0.147\n",
      "[4,  4800] loss: 0.102\n",
      "[4,  4900] loss: 0.116\n",
      "[4,  5000] loss: 0.119\n",
      "[4,  5100] loss: 0.130\n",
      "[4,  5200] loss: 0.101\n",
      "[4,  5300] loss: 0.110\n",
      "[4,  5400] loss: 0.121\n",
      "[4,  5500] loss: 0.125\n",
      "[4,  5600] loss: 0.133\n",
      "[4,  5700] loss: 0.208\n",
      "[4,  5800] loss: 0.101\n",
      "[4,  5900] loss: 0.112\n",
      "[4,  6000] loss: 0.113\n",
      "[4,  6100] loss: 0.125\n",
      "[4,  6200] loss: 0.114\n",
      "[4,  6300] loss: 0.129\n",
      "[4,  6400] loss: 0.114\n",
      "[4,  6500] loss: 0.113\n",
      "[4,  6600] loss: 0.119\n",
      "[4,  6700] loss: 0.113\n",
      "[4,  6800] loss: 0.132\n",
      "[4,  6900] loss: 0.136\n",
      "[4,  7000] loss: 0.116\n",
      "[4,  7100] loss: 0.125\n",
      "[4,  7200] loss: 0.121\n",
      "[4,  7300] loss: 0.156\n",
      "[4,  7400] loss: 0.117\n",
      "[4,  7500] loss: 0.119\n",
      "[4,  7600] loss: 0.133\n",
      "[4,  7700] loss: 0.117\n",
      "[4,  7800] loss: 0.121\n",
      "[4,  7900] loss: 0.116\n",
      "[4,  8000] loss: 0.108\n",
      "[4,  8100] loss: 0.114\n",
      "[4,  8200] loss: 0.117\n",
      "[4,  8300] loss: 0.112\n",
      "[4,  8400] loss: 0.112\n",
      "[4,  8500] loss: 0.114\n",
      "[4,  8600] loss: 0.111\n",
      "[4,  8700] loss: 0.116\n",
      "[4,  8800] loss: 0.109\n",
      "[4,  8900] loss: 0.127\n",
      "[4,  9000] loss: 0.125\n",
      "[4,  9100] loss: 0.099\n",
      "[4,  9200] loss: 0.126\n",
      "[4,  9300] loss: 0.120\n",
      "[4,  9400] loss: 0.123\n",
      "[4,  9500] loss: 0.110\n",
      "[4,  9600] loss: 0.110\n",
      "[4,  9700] loss: 0.117\n",
      "[4,  9800] loss: 0.116\n",
      "[4,  9900] loss: 0.111\n",
      "[4, 10000] loss: 0.113\n",
      "[4, 10100] loss: 0.125\n",
      "[4, 10200] loss: 0.111\n",
      "[4, 10300] loss: 0.113\n",
      "[4, 10400] loss: 0.121\n",
      "[4, 10500] loss: 0.110\n",
      "[4, 10600] loss: 0.100\n",
      "[4, 10700] loss: 0.118\n",
      "[4, 10800] loss: 0.126\n",
      "[4, 10900] loss: 0.111\n",
      "[4, 11000] loss: 0.111\n",
      "[4, 11100] loss: 0.102\n",
      "[4, 11200] loss: 0.114\n",
      "[4, 11300] loss: 0.114\n",
      "[4, 11400] loss: 0.104\n",
      "[4, 11500] loss: 0.111\n",
      "[4, 11600] loss: 0.119\n",
      "[4, 11700] loss: 0.119\n",
      "[4, 11800] loss: 0.106\n",
      "[4, 11900] loss: 0.118\n",
      "[4, 12000] loss: 0.118\n",
      "[4, 12100] loss: 0.106\n",
      "[4, 12200] loss: 0.104\n",
      "[4, 12300] loss: 0.120\n",
      "[4, 12400] loss: 0.118\n",
      "[4, 12500] loss: 0.115\n",
      "[4, 12600] loss: 0.129\n",
      "Epoch 4 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9691    0.9992    0.9839   3055493\n",
      "         1.0     0.9732    0.4753    0.6387    185421\n",
      "\n",
      "    accuracy                         0.9692   3240914\n",
      "   macro avg     0.9711    0.7372    0.8113   3240914\n",
      "weighted avg     0.9693    0.9692    0.9642   3240914\n",
      "\n",
      "AUC: 0.9194\n",
      "[5,   100] loss: 0.107\n",
      "[5,   200] loss: 0.103\n",
      "[5,   300] loss: 0.125\n",
      "[5,   400] loss: 0.114\n",
      "[5,   500] loss: 0.113\n",
      "[5,   600] loss: 0.115\n",
      "[5,   700] loss: 0.100\n",
      "[5,   800] loss: 0.105\n",
      "[5,   900] loss: 0.116\n",
      "[5,  1000] loss: 0.120\n",
      "[5,  1100] loss: 0.114\n",
      "[5,  1200] loss: 0.117\n",
      "[5,  1300] loss: 0.111\n",
      "[5,  1400] loss: 0.115\n",
      "[5,  1500] loss: 0.095\n",
      "[5,  1600] loss: 0.107\n",
      "[5,  1700] loss: 0.102\n",
      "[5,  1800] loss: 0.129\n",
      "[5,  1900] loss: 0.120\n",
      "[5,  2000] loss: 0.114\n",
      "[5,  2100] loss: 0.109\n",
      "[5,  2200] loss: 0.115\n",
      "[5,  2300] loss: 0.118\n",
      "[5,  2400] loss: 0.105\n",
      "[5,  2500] loss: 0.111\n",
      "[5,  2600] loss: 0.103\n",
      "[5,  2700] loss: 0.106\n",
      "[5,  2800] loss: 0.132\n",
      "[5,  2900] loss: 0.108\n",
      "[5,  3000] loss: 0.113\n",
      "[5,  3100] loss: 0.124\n",
      "[5,  3200] loss: 0.100\n",
      "[5,  3300] loss: 0.111\n",
      "[5,  3400] loss: 0.117\n",
      "[5,  3500] loss: 0.112\n",
      "[5,  3600] loss: 0.101\n",
      "[5,  3700] loss: 0.124\n",
      "[5,  3800] loss: 0.112\n",
      "[5,  3900] loss: 0.115\n",
      "[5,  4000] loss: 0.107\n",
      "[5,  4100] loss: 0.112\n",
      "[5,  4200] loss: 0.138\n",
      "[5,  4300] loss: 0.118\n",
      "[5,  4400] loss: 0.108\n",
      "[5,  4500] loss: 0.108\n",
      "[5,  4600] loss: 0.109\n",
      "[5,  4700] loss: 0.111\n",
      "[5,  4800] loss: 0.103\n",
      "[5,  4900] loss: 0.115\n",
      "[5,  5000] loss: 0.102\n",
      "[5,  5100] loss: 0.110\n",
      "[5,  5200] loss: 0.118\n",
      "[5,  5300] loss: 0.109\n",
      "[5,  5400] loss: 0.100\n",
      "[5,  5500] loss: 0.105\n",
      "[5,  5600] loss: 0.098\n",
      "[5,  5700] loss: 0.098\n",
      "[5,  5800] loss: 0.105\n",
      "[5,  5900] loss: 0.100\n",
      "[5,  6000] loss: 0.112\n",
      "[5,  6100] loss: 0.128\n",
      "[5,  6200] loss: 0.125\n",
      "[5,  6300] loss: 0.096\n",
      "[5,  6400] loss: 0.100\n",
      "[5,  6500] loss: 0.098\n",
      "[5,  6600] loss: 0.104\n",
      "[5,  6700] loss: 0.107\n",
      "[5,  6800] loss: 0.097\n",
      "[5,  6900] loss: 0.098\n",
      "[5,  7000] loss: 0.103\n",
      "[5,  7100] loss: 0.090\n",
      "[5,  7200] loss: 0.118\n",
      "[5,  7300] loss: 0.119\n",
      "[5,  7400] loss: 0.105\n",
      "[5,  7500] loss: 0.112\n",
      "[5,  7600] loss: 0.100\n",
      "[5,  7700] loss: 0.110\n",
      "[5,  7800] loss: 0.096\n",
      "[5,  7900] loss: 0.112\n",
      "[5,  8000] loss: 0.099\n",
      "[5,  8100] loss: 0.105\n",
      "[5,  8200] loss: 0.108\n",
      "[5,  8300] loss: 0.106\n",
      "[5,  8400] loss: 0.100\n",
      "[5,  8500] loss: 0.107\n",
      "[5,  8600] loss: 0.096\n",
      "[5,  8700] loss: 0.106\n",
      "[5,  8800] loss: 0.100\n",
      "[5,  8900] loss: 0.112\n",
      "[5,  9000] loss: 0.090\n",
      "[5,  9100] loss: 0.116\n",
      "[5,  9200] loss: 0.110\n",
      "[5,  9300] loss: 0.100\n",
      "[5,  9400] loss: 0.126\n",
      "[5,  9500] loss: 0.103\n",
      "[5,  9600] loss: 0.095\n",
      "[5,  9700] loss: 0.103\n",
      "[5,  9800] loss: 0.104\n",
      "[5,  9900] loss: 0.090\n",
      "[5, 10000] loss: 0.108\n",
      "[5, 10100] loss: 0.101\n",
      "[5, 10200] loss: 0.096\n",
      "[5, 10300] loss: 0.091\n",
      "[5, 10400] loss: 0.091\n",
      "[5, 10500] loss: 0.096\n",
      "[5, 10600] loss: 0.104\n",
      "[5, 10700] loss: 0.092\n",
      "[5, 10800] loss: 0.100\n",
      "[5, 10900] loss: 0.101\n",
      "[5, 11000] loss: 0.108\n",
      "[5, 11100] loss: 0.098\n",
      "[5, 11200] loss: 0.099\n",
      "[5, 11300] loss: 0.096\n",
      "[5, 11400] loss: 0.105\n",
      "[5, 11500] loss: 0.097\n",
      "[5, 11600] loss: 0.111\n",
      "[5, 11700] loss: 0.110\n",
      "[5, 11800] loss: 0.097\n",
      "[5, 11900] loss: 0.099\n",
      "[5, 12000] loss: 0.101\n",
      "[5, 12100] loss: 0.126\n",
      "[5, 12200] loss: 0.147\n",
      "[5, 12300] loss: 0.116\n",
      "[5, 12400] loss: 0.092\n",
      "[5, 12500] loss: 0.099\n",
      "[5, 12600] loss: 0.104\n",
      "Epoch 5 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9721    0.9992    0.9855   3055493\n",
      "         1.0     0.9768    0.5274    0.6850    185421\n",
      "\n",
      "    accuracy                         0.9722   3240914\n",
      "   macro avg     0.9745    0.7633    0.8352   3240914\n",
      "weighted avg     0.9724    0.9722    0.9683   3240914\n",
      "\n",
      "AUC: 0.9334\n",
      "[6,   100] loss: 0.101\n",
      "[6,   200] loss: 0.104\n",
      "[6,   300] loss: 0.099\n",
      "[6,   400] loss: 0.115\n",
      "[6,   500] loss: 0.090\n",
      "[6,   600] loss: 0.094\n",
      "[6,   700] loss: 0.109\n",
      "[6,   800] loss: 0.094\n",
      "[6,   900] loss: 0.100\n",
      "[6,  1000] loss: 0.092\n",
      "[6,  1100] loss: 0.112\n",
      "[6,  1200] loss: 0.106\n",
      "[6,  1300] loss: 0.095\n",
      "[6,  1400] loss: 0.101\n",
      "[6,  1500] loss: 0.094\n",
      "[6,  1600] loss: 0.109\n",
      "[6,  1700] loss: 0.088\n",
      "[6,  1800] loss: 0.103\n",
      "[6,  1900] loss: 0.092\n",
      "[6,  2000] loss: 0.097\n",
      "[6,  2100] loss: 0.100\n",
      "[6,  2200] loss: 0.097\n",
      "[6,  2300] loss: 0.095\n",
      "[6,  2400] loss: 0.098\n",
      "[6,  2500] loss: 0.098\n",
      "[6,  2600] loss: 0.093\n",
      "[6,  2700] loss: 0.108\n",
      "[6,  2800] loss: 0.093\n",
      "[6,  2900] loss: 0.097\n",
      "[6,  3000] loss: 0.092\n",
      "[6,  3100] loss: 0.109\n",
      "[6,  3200] loss: 0.091\n",
      "[6,  3300] loss: 0.097\n",
      "[6,  3400] loss: 0.083\n",
      "[6,  3500] loss: 0.100\n",
      "[6,  3600] loss: 0.092\n",
      "[6,  3700] loss: 0.088\n",
      "[6,  3800] loss: 0.098\n",
      "[6,  3900] loss: 0.104\n",
      "[6,  4000] loss: 0.080\n",
      "[6,  4100] loss: 0.106\n",
      "[6,  4200] loss: 0.102\n",
      "[6,  4300] loss: 0.083\n",
      "[6,  4400] loss: 0.089\n",
      "[6,  4500] loss: 0.096\n",
      "[6,  4600] loss: 0.090\n",
      "[6,  4700] loss: 0.101\n",
      "[6,  4800] loss: 0.086\n",
      "[6,  4900] loss: 0.105\n",
      "[6,  5000] loss: 0.090\n",
      "[6,  5100] loss: 0.087\n",
      "[6,  5200] loss: 0.095\n",
      "[6,  5300] loss: 0.101\n",
      "[6,  5400] loss: 0.091\n",
      "[6,  5500] loss: 0.083\n",
      "[6,  5600] loss: 0.083\n",
      "[6,  5700] loss: 0.082\n",
      "[6,  5800] loss: 0.084\n",
      "[6,  5900] loss: 0.090\n",
      "[6,  6000] loss: 0.077\n",
      "[6,  6100] loss: 0.086\n",
      "[6,  6200] loss: 0.085\n",
      "[6,  6300] loss: 0.121\n",
      "[6,  6400] loss: 0.081\n",
      "[6,  6500] loss: 0.102\n",
      "[6,  6600] loss: 0.091\n",
      "[6,  6700] loss: 0.097\n",
      "[6,  6800] loss: 0.083\n",
      "[6,  6900] loss: 0.086\n",
      "[6,  7000] loss: 0.078\n",
      "[6,  7100] loss: 0.096\n",
      "[6,  7200] loss: 0.090\n",
      "[6,  7300] loss: 0.093\n",
      "[6,  7400] loss: 0.082\n",
      "[6,  7500] loss: 0.095\n",
      "[6,  7600] loss: 0.086\n",
      "[6,  7700] loss: 0.097\n",
      "[6,  7800] loss: 0.092\n",
      "[6,  7900] loss: 0.087\n",
      "[6,  8000] loss: 0.106\n",
      "[6,  8100] loss: 0.087\n",
      "[6,  8200] loss: 0.086\n",
      "[6,  8300] loss: 0.089\n",
      "[6,  8400] loss: 0.088\n",
      "[6,  8500] loss: 0.084\n",
      "[6,  8600] loss: 0.093\n",
      "[6,  8700] loss: 0.083\n",
      "[6,  8800] loss: 0.080\n",
      "[6,  8900] loss: 0.096\n",
      "[6,  9000] loss: 0.105\n",
      "[6,  9100] loss: 0.090\n",
      "[6,  9200] loss: 0.105\n",
      "[6,  9300] loss: 0.107\n",
      "[6,  9400] loss: 0.101\n",
      "[6,  9500] loss: 0.083\n",
      "[6,  9600] loss: 0.072\n",
      "[6,  9700] loss: 0.092\n",
      "[6,  9800] loss: 0.079\n",
      "[6,  9900] loss: 0.086\n",
      "[6, 10000] loss: 0.087\n",
      "[6, 10100] loss: 0.085\n",
      "[6, 10200] loss: 0.084\n",
      "[6, 10300] loss: 0.079\n",
      "[6, 10400] loss: 0.074\n",
      "[6, 10500] loss: 0.082\n",
      "[6, 10600] loss: 0.092\n",
      "[6, 10700] loss: 0.085\n",
      "[6, 10800] loss: 0.083\n",
      "[6, 10900] loss: 0.088\n",
      "[6, 11000] loss: 0.099\n",
      "[6, 11100] loss: 0.083\n",
      "[6, 11200] loss: 0.108\n",
      "[6, 11300] loss: 0.072\n",
      "[6, 11400] loss: 0.079\n",
      "[6, 11500] loss: 0.095\n",
      "[6, 11600] loss: 0.079\n",
      "[6, 11700] loss: 0.080\n",
      "[6, 11800] loss: 0.079\n",
      "[6, 11900] loss: 0.091\n",
      "[6, 12000] loss: 0.076\n",
      "[6, 12100] loss: 0.097\n",
      "[6, 12200] loss: 0.080\n",
      "[6, 12300] loss: 0.088\n",
      "[6, 12400] loss: 0.086\n",
      "[6, 12500] loss: 0.078\n",
      "[6, 12600] loss: 0.086\n",
      "Epoch 6 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9758    0.9994    0.9875   3055493\n",
      "         1.0     0.9836    0.5924    0.7394    185421\n",
      "\n",
      "    accuracy                         0.9761   3240914\n",
      "   macro avg     0.9797    0.7959    0.8635   3240914\n",
      "weighted avg     0.9763    0.9761    0.9733   3240914\n",
      "\n",
      "AUC: 0.9504\n",
      "[7,   100] loss: 0.077\n",
      "[7,   200] loss: 0.082\n",
      "[7,   300] loss: 0.096\n",
      "[7,   400] loss: 0.065\n",
      "[7,   500] loss: 0.100\n",
      "[7,   600] loss: 0.082\n",
      "[7,   700] loss: 0.077\n",
      "[7,   800] loss: 0.075\n",
      "[7,   900] loss: 0.075\n",
      "[7,  1000] loss: 0.094\n",
      "[7,  1100] loss: 0.073\n",
      "[7,  1200] loss: 0.082\n",
      "[7,  1300] loss: 0.090\n",
      "[7,  1400] loss: 0.076\n",
      "[7,  1500] loss: 0.086\n",
      "[7,  1600] loss: 0.064\n",
      "[7,  1700] loss: 0.064\n",
      "[7,  1800] loss: 0.073\n",
      "[7,  1900] loss: 0.072\n",
      "[7,  2000] loss: 0.064\n",
      "[7,  2100] loss: 0.069\n",
      "[7,  2200] loss: 0.088\n",
      "[7,  2300] loss: 0.079\n",
      "[7,  2400] loss: 0.072\n",
      "[7,  2500] loss: 0.074\n",
      "[7,  2600] loss: 0.060\n",
      "[7,  2700] loss: 0.083\n",
      "[7,  2800] loss: 0.076\n",
      "[7,  2900] loss: 0.075\n",
      "[7,  3000] loss: 0.074\n",
      "[7,  3100] loss: 0.065\n",
      "[7,  3200] loss: 0.078\n",
      "[7,  3300] loss: 0.078\n",
      "[7,  3400] loss: 0.063\n",
      "[7,  3500] loss: 0.086\n",
      "[7,  3600] loss: 0.080\n",
      "[7,  3700] loss: 0.078\n",
      "[7,  3800] loss: 0.073\n",
      "[7,  3900] loss: 0.063\n",
      "[7,  4000] loss: 0.089\n",
      "[7,  4100] loss: 0.066\n",
      "[7,  4200] loss: 0.072\n",
      "[7,  4300] loss: 0.075\n",
      "[7,  4400] loss: 0.063\n",
      "[7,  4500] loss: 0.066\n",
      "[7,  4600] loss: 0.070\n",
      "[7,  4700] loss: 0.078\n",
      "[7,  4800] loss: 0.073\n",
      "[7,  4900] loss: 0.068\n",
      "[7,  5000] loss: 0.070\n",
      "[7,  5100] loss: 0.073\n",
      "[7,  5200] loss: 0.075\n",
      "[7,  5300] loss: 0.069\n",
      "[7,  5400] loss: 0.061\n",
      "[7,  5500] loss: 0.064\n",
      "[7,  5600] loss: 0.070\n",
      "[7,  5700] loss: 0.068\n",
      "[7,  5800] loss: 0.061\n",
      "[7,  5900] loss: 0.058\n",
      "[7,  6000] loss: 0.091\n",
      "[7,  6100] loss: 0.065\n",
      "[7,  6200] loss: 0.058\n",
      "[7,  6300] loss: 0.056\n",
      "[7,  6400] loss: 0.058\n",
      "[7,  6500] loss: 0.060\n",
      "[7,  6600] loss: 0.063\n",
      "[7,  6700] loss: 0.081\n",
      "[7,  6800] loss: 0.074\n",
      "[7,  6900] loss: 0.063\n",
      "[7,  7000] loss: 0.064\n",
      "[7,  7100] loss: 0.077\n",
      "[7,  7200] loss: 0.071\n",
      "[7,  7300] loss: 0.057\n",
      "[7,  7400] loss: 0.060\n",
      "[7,  7500] loss: 0.084\n",
      "[7,  7600] loss: 0.098\n",
      "[7,  7700] loss: 0.081\n",
      "[7,  7800] loss: 0.056\n",
      "[7,  7900] loss: 0.068\n",
      "[7,  8000] loss: 0.069\n",
      "[7,  8100] loss: 0.054\n",
      "[7,  8200] loss: 0.051\n",
      "[7,  8300] loss: 0.065\n",
      "[7,  8400] loss: 0.074\n",
      "[7,  8500] loss: 0.057\n",
      "[7,  8600] loss: 0.061\n",
      "[7,  8700] loss: 0.050\n",
      "[7,  8800] loss: 0.073\n",
      "[7,  8900] loss: 0.062\n",
      "[7,  9000] loss: 0.062\n",
      "[7,  9100] loss: 0.061\n",
      "[7,  9200] loss: 0.065\n",
      "[7,  9300] loss: 0.054\n",
      "[7,  9400] loss: 0.076\n",
      "[7,  9500] loss: 0.068\n",
      "[7,  9600] loss: 0.070\n",
      "[7,  9700] loss: 0.060\n",
      "[7,  9800] loss: 0.059\n",
      "[7,  9900] loss: 0.059\n",
      "[7, 10000] loss: 0.067\n",
      "[7, 10100] loss: 0.066\n",
      "[7, 10200] loss: 0.061\n",
      "[7, 10300] loss: 0.059\n",
      "[7, 10400] loss: 0.061\n",
      "[7, 10500] loss: 0.061\n",
      "[7, 10600] loss: 0.066\n",
      "[7, 10700] loss: 0.161\n",
      "[7, 10800] loss: 0.062\n",
      "[7, 10900] loss: 0.052\n",
      "[7, 11000] loss: 0.067\n",
      "[7, 11100] loss: 0.055\n",
      "[7, 11200] loss: 0.063\n",
      "[7, 11300] loss: 0.075\n",
      "[7, 11400] loss: 0.069\n",
      "[7, 11500] loss: 0.062\n",
      "[7, 11600] loss: 0.051\n",
      "[7, 11700] loss: 0.055\n",
      "[7, 11800] loss: 0.060\n",
      "[7, 11900] loss: 0.057\n",
      "[7, 12000] loss: 0.072\n",
      "[7, 12100] loss: 0.072\n",
      "[7, 12200] loss: 0.076\n",
      "[7, 12300] loss: 0.059\n",
      "[7, 12400] loss: 0.060\n",
      "[7, 12500] loss: 0.055\n",
      "[7, 12600] loss: 0.054\n",
      "Epoch 7 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9827    0.9993    0.9909   3055493\n",
      "         1.0     0.9831    0.7108    0.8251    185421\n",
      "\n",
      "    accuracy                         0.9828   3240914\n",
      "   macro avg     0.9829    0.8550    0.9080   3240914\n",
      "weighted avg     0.9828    0.9828    0.9814   3240914\n",
      "\n",
      "AUC: 0.9716\n",
      "[8,   100] loss: 0.069\n",
      "[8,   200] loss: 0.071\n",
      "[8,   300] loss: 0.072\n",
      "[8,   400] loss: 0.051\n",
      "[8,   500] loss: 0.064\n",
      "[8,   600] loss: 0.079\n",
      "[8,   700] loss: 0.078\n",
      "[8,   800] loss: 0.058\n",
      "[8,   900] loss: 0.054\n",
      "[8,  1000] loss: 0.052\n",
      "[8,  1100] loss: 0.077\n",
      "[8,  1200] loss: 0.062\n",
      "[8,  1300] loss: 0.056\n",
      "[8,  1400] loss: 0.065\n",
      "[8,  1500] loss: 0.090\n",
      "[8,  1600] loss: 0.058\n",
      "[8,  1700] loss: 0.061\n",
      "[8,  1800] loss: 0.050\n",
      "[8,  1900] loss: 0.054\n",
      "[8,  2000] loss: 0.057\n",
      "[8,  2100] loss: 0.055\n",
      "[8,  2200] loss: 0.056\n",
      "[8,  2300] loss: 0.068\n",
      "[8,  2400] loss: 0.052\n",
      "[8,  2500] loss: 0.054\n",
      "[8,  2600] loss: 0.054\n",
      "[8,  2700] loss: 0.061\n",
      "[8,  2800] loss: 0.055\n",
      "[8,  2900] loss: 0.058\n",
      "[8,  3000] loss: 0.047\n",
      "[8,  3100] loss: 0.049\n",
      "[8,  3200] loss: 0.053\n",
      "[8,  3300] loss: 0.048\n",
      "[8,  3400] loss: 0.044\n",
      "[8,  3500] loss: 0.054\n",
      "[8,  3600] loss: 0.060\n",
      "[8,  3700] loss: 0.064\n",
      "[8,  3800] loss: 0.057\n",
      "[8,  3900] loss: 0.051\n",
      "[8,  4000] loss: 0.058\n",
      "[8,  4100] loss: 0.054\n",
      "[8,  4200] loss: 0.076\n",
      "[8,  4300] loss: 0.041\n",
      "[8,  4400] loss: 0.049\n",
      "[8,  4500] loss: 0.051\n",
      "[8,  4600] loss: 0.042\n",
      "[8,  4700] loss: 0.057\n",
      "[8,  4800] loss: 0.050\n",
      "[8,  4900] loss: 0.055\n",
      "[8,  5000] loss: 0.055\n",
      "[8,  5100] loss: 0.045\n",
      "[8,  5200] loss: 0.054\n",
      "[8,  5300] loss: 0.065\n",
      "[8,  5400] loss: 0.051\n",
      "[8,  5500] loss: 0.070\n",
      "[8,  5600] loss: 0.053\n",
      "[8,  5700] loss: 0.048\n",
      "[8,  5800] loss: 0.053\n",
      "[8,  5900] loss: 0.065\n",
      "[8,  6000] loss: 0.057\n",
      "[8,  6100] loss: 0.054\n",
      "[8,  6200] loss: 0.052\n",
      "[8,  6300] loss: 0.061\n",
      "[8,  6400] loss: 0.047\n",
      "[8,  6500] loss: 0.049\n",
      "[8,  6600] loss: 0.056\n",
      "[8,  6700] loss: 0.056\n",
      "[8,  6800] loss: 0.075\n",
      "[8,  6900] loss: 0.049\n",
      "[8,  7000] loss: 0.052\n",
      "[8,  7100] loss: 0.054\n",
      "[8,  7200] loss: 0.037\n",
      "[8,  7300] loss: 0.050\n",
      "[8,  7400] loss: 0.043\n",
      "[8,  7500] loss: 0.056\n",
      "[8,  7600] loss: 0.054\n",
      "[8,  7700] loss: 0.041\n",
      "[8,  7800] loss: 0.050\n",
      "[8,  7900] loss: 0.047\n",
      "[8,  8000] loss: 0.046\n",
      "[8,  8100] loss: 0.053\n",
      "[8,  8200] loss: 0.056\n",
      "[8,  8300] loss: 0.056\n",
      "[8,  8400] loss: 0.043\n",
      "[8,  8500] loss: 0.046\n",
      "[8,  8600] loss: 0.063\n",
      "[8,  8700] loss: 0.054\n",
      "[8,  8800] loss: 0.044\n",
      "[8,  8900] loss: 0.061\n",
      "[8,  9000] loss: 0.049\n",
      "[8,  9100] loss: 0.039\n",
      "[8,  9200] loss: 0.065\n",
      "[8,  9300] loss: 0.052\n",
      "[8,  9400] loss: 0.049\n",
      "[8,  9500] loss: 0.052\n",
      "[8,  9600] loss: 0.039\n",
      "[8,  9700] loss: 0.048\n",
      "[8,  9800] loss: 0.040\n",
      "[8,  9900] loss: 0.052\n",
      "[8, 10000] loss: 0.047\n",
      "[8, 10100] loss: 0.042\n",
      "[8, 10200] loss: 0.056\n",
      "[8, 10300] loss: 0.047\n",
      "[8, 10400] loss: 0.046\n",
      "[8, 10500] loss: 0.062\n",
      "[8, 10600] loss: 0.086\n",
      "[8, 10700] loss: 0.046\n",
      "[8, 10800] loss: 0.052\n",
      "[8, 10900] loss: 0.044\n",
      "[8, 11000] loss: 0.044\n",
      "[8, 11100] loss: 0.051\n",
      "[8, 11200] loss: 0.038\n",
      "[8, 11300] loss: 0.047\n",
      "[8, 11400] loss: 0.041\n",
      "[8, 11500] loss: 0.045\n",
      "[8, 11600] loss: 0.059\n",
      "[8, 11700] loss: 0.046\n",
      "[8, 11800] loss: 0.050\n",
      "[8, 11900] loss: 0.045\n",
      "[8, 12000] loss: 0.056\n",
      "[8, 12100] loss: 0.042\n",
      "[8, 12200] loss: 0.057\n",
      "[8, 12300] loss: 0.036\n",
      "[8, 12400] loss: 0.051\n",
      "[8, 12500] loss: 0.034\n",
      "[8, 12600] loss: 0.041\n",
      "Epoch 8 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9885    0.9990    0.9938   3055493\n",
      "         1.0     0.9809    0.8092    0.8868    185421\n",
      "\n",
      "    accuracy                         0.9882   3240914\n",
      "   macro avg     0.9847    0.9041    0.9403   3240914\n",
      "weighted avg     0.9881    0.9882    0.9876   3240914\n",
      "\n",
      "AUC: 0.9816\n",
      "[9,   100] loss: 0.042\n",
      "[9,   200] loss: 0.057\n",
      "[9,   300] loss: 0.051\n",
      "[9,   400] loss: 0.051\n",
      "[9,   500] loss: 0.055\n",
      "[9,   600] loss: 0.038\n",
      "[9,   700] loss: 0.062\n",
      "[9,   800] loss: 0.037\n",
      "[9,   900] loss: 0.048\n",
      "[9,  1000] loss: 0.039\n",
      "[9,  1100] loss: 0.042\n",
      "[9,  1200] loss: 0.041\n",
      "[9,  1300] loss: 0.048\n",
      "[9,  1400] loss: 0.042\n",
      "[9,  1500] loss: 0.049\n",
      "[9,  1600] loss: 0.042\n",
      "[9,  1700] loss: 0.040\n",
      "[9,  1800] loss: 0.038\n",
      "[9,  1900] loss: 0.047\n",
      "[9,  2000] loss: 0.041\n",
      "[9,  2100] loss: 0.050\n",
      "[9,  2200] loss: 0.053\n",
      "[9,  2300] loss: 0.043\n",
      "[9,  2400] loss: 0.038\n",
      "[9,  2500] loss: 0.042\n",
      "[9,  2600] loss: 0.038\n",
      "[9,  2700] loss: 0.039\n",
      "[9,  2800] loss: 0.037\n",
      "[9,  2900] loss: 0.050\n",
      "[9,  3000] loss: 0.041\n",
      "[9,  3100] loss: 0.036\n",
      "[9,  3200] loss: 0.039\n",
      "[9,  3300] loss: 0.044\n",
      "[9,  3400] loss: 0.040\n",
      "[9,  3500] loss: 0.044\n",
      "[9,  3600] loss: 0.039\n",
      "[9,  3700] loss: 0.042\n",
      "[9,  3800] loss: 0.055\n",
      "[9,  3900] loss: 0.039\n",
      "[9,  4000] loss: 0.035\n",
      "[9,  4100] loss: 0.039\n",
      "[9,  4200] loss: 0.048\n",
      "[9,  4300] loss: 0.040\n",
      "[9,  4400] loss: 0.036\n",
      "[9,  4500] loss: 0.033\n",
      "[9,  4600] loss: 0.027\n",
      "[9,  4700] loss: 0.038\n",
      "[9,  4800] loss: 0.035\n",
      "[9,  4900] loss: 0.034\n",
      "[9,  5000] loss: 0.035\n",
      "[9,  5100] loss: 0.042\n",
      "[9,  5200] loss: 0.048\n",
      "[9,  5300] loss: 1.583\n",
      "[9,  5400] loss: 0.132\n",
      "[9,  5500] loss: 0.045\n",
      "[9,  5600] loss: 0.034\n",
      "[9,  5700] loss: 0.030\n",
      "[9,  5800] loss: 0.039\n",
      "[9,  5900] loss: 0.042\n",
      "[9,  6000] loss: 0.047\n",
      "[9,  6100] loss: 0.038\n",
      "[9,  6200] loss: 0.036\n",
      "[9,  6300] loss: 0.035\n",
      "[9,  6400] loss: 0.039\n",
      "[9,  6500] loss: 0.041\n",
      "[9,  6600] loss: 0.039\n",
      "[9,  6700] loss: 0.029\n",
      "[9,  6800] loss: 0.041\n",
      "[9,  6900] loss: 0.041\n",
      "[9,  7000] loss: 0.030\n",
      "[9,  7100] loss: 0.034\n",
      "[9,  7200] loss: 0.034\n",
      "[9,  7300] loss: 0.044\n",
      "[9,  7400] loss: 0.037\n",
      "[9,  7500] loss: 0.053\n",
      "[9,  7600] loss: 0.035\n",
      "[9,  7700] loss: 0.038\n",
      "[9,  7800] loss: 0.046\n",
      "[9,  7900] loss: 0.038\n",
      "[9,  8000] loss: 0.041\n",
      "[9,  8100] loss: 0.111\n",
      "[9,  8200] loss: 0.043\n",
      "[9,  8300] loss: 0.044\n",
      "[9,  8400] loss: 0.031\n",
      "[9,  8500] loss: 0.034\n",
      "[9,  8600] loss: 0.029\n",
      "[9,  8700] loss: 0.035\n",
      "[9,  8800] loss: 0.051\n",
      "[9,  8900] loss: 0.048\n",
      "[9,  9000] loss: 0.044\n",
      "[9,  9100] loss: 0.034\n",
      "[9,  9200] loss: 0.042\n",
      "[9,  9300] loss: 0.033\n",
      "[9,  9400] loss: 0.034\n",
      "[9,  9500] loss: 0.041\n",
      "[9,  9600] loss: 0.045\n",
      "[9,  9700] loss: 0.045\n",
      "[9,  9800] loss: 0.048\n",
      "[9,  9900] loss: 0.037\n",
      "[9, 10000] loss: 0.038\n",
      "[9, 10100] loss: 0.045\n",
      "[9, 10200] loss: 0.053\n",
      "[9, 10300] loss: 0.046\n",
      "[9, 10400] loss: 0.049\n",
      "[9, 10500] loss: 0.042\n",
      "[9, 10600] loss: 0.042\n",
      "[9, 10700] loss: 0.035\n",
      "[9, 10800] loss: 0.042\n",
      "[9, 10900] loss: 0.044\n",
      "[9, 11000] loss: 0.042\n",
      "[9, 11100] loss: 0.034\n",
      "[9, 11200] loss: 0.037\n",
      "[9, 11300] loss: 0.031\n",
      "[9, 11400] loss: 0.036\n",
      "[9, 11500] loss: 0.046\n",
      "[9, 11600] loss: 0.068\n",
      "[9, 11700] loss: 0.030\n",
      "[9, 11800] loss: 0.042\n",
      "[9, 11900] loss: 0.027\n",
      "[9, 12000] loss: 0.033\n",
      "[9, 12100] loss: 0.037\n",
      "[9, 12200] loss: 0.037\n",
      "[9, 12300] loss: 0.032\n",
      "[9, 12400] loss: 0.042\n",
      "[9, 12500] loss: 0.042\n",
      "[9, 12600] loss: 0.032\n",
      "Epoch 9 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9914    0.9990    0.9952   3055493\n",
      "         1.0     0.9818    0.8565    0.9149    185421\n",
      "\n",
      "    accuracy                         0.9909   3240914\n",
      "   macro avg     0.9866    0.9278    0.9550   3240914\n",
      "weighted avg     0.9908    0.9909    0.9906   3240914\n",
      "\n",
      "AUC: 0.9810\n",
      "[10,   100] loss: 0.032\n",
      "[10,   200] loss: 0.048\n",
      "[10,   300] loss: 0.030\n",
      "[10,   400] loss: 0.030\n",
      "[10,   500] loss: 0.034\n",
      "[10,   600] loss: 0.032\n",
      "[10,   700] loss: 0.033\n",
      "[10,   800] loss: 0.033\n",
      "[10,   900] loss: 0.040\n",
      "[10,  1000] loss: 0.029\n",
      "[10,  1100] loss: 0.034\n",
      "[10,  1200] loss: 0.030\n",
      "[10,  1300] loss: 0.037\n",
      "[10,  1400] loss: 0.059\n",
      "[10,  1500] loss: 0.031\n",
      "[10,  1600] loss: 0.042\n",
      "[10,  1700] loss: 0.050\n",
      "[10,  1800] loss: 0.039\n",
      "[10,  1900] loss: 0.037\n",
      "[10,  2000] loss: 0.034\n",
      "[10,  2100] loss: 0.032\n",
      "[10,  2200] loss: 0.044\n",
      "[10,  2300] loss: 0.033\n",
      "[10,  2400] loss: 0.036\n",
      "[10,  2500] loss: 0.034\n",
      "[10,  2600] loss: 0.033\n",
      "[10,  2700] loss: 0.029\n",
      "[10,  2800] loss: 0.033\n",
      "[10,  2900] loss: 0.031\n",
      "[10,  3000] loss: 0.039\n",
      "[10,  3100] loss: 0.037\n",
      "[10,  3200] loss: 1.493\n",
      "[10,  3300] loss: 0.880\n",
      "[10,  3400] loss: 0.033\n",
      "[10,  3500] loss: 0.027\n",
      "[10,  3600] loss: 0.028\n",
      "[10,  3700] loss: 0.034\n",
      "[10,  3800] loss: 0.026\n",
      "[10,  3900] loss: 0.027\n",
      "[10,  4000] loss: 0.039\n",
      "[10,  4100] loss: 0.027\n",
      "[10,  4200] loss: 0.027\n",
      "[10,  4300] loss: 0.032\n",
      "[10,  4400] loss: 0.037\n",
      "[10,  4500] loss: 0.034\n",
      "[10,  4600] loss: 0.031\n",
      "[10,  4700] loss: 0.032\n",
      "[10,  4800] loss: 0.038\n",
      "[10,  4900] loss: 0.026\n",
      "[10,  5000] loss: 0.031\n",
      "[10,  5100] loss: 0.029\n",
      "[10,  5200] loss: 0.038\n",
      "[10,  5300] loss: 0.035\n",
      "[10,  5400] loss: 0.033\n",
      "[10,  5500] loss: 0.043\n",
      "[10,  5600] loss: 0.031\n",
      "[10,  5700] loss: 0.036\n",
      "[10,  5800] loss: 0.050\n",
      "[10,  5900] loss: 0.037\n",
      "[10,  6000] loss: 0.034\n",
      "[10,  6100] loss: 0.035\n",
      "[10,  6200] loss: 0.028\n",
      "[10,  6300] loss: 0.029\n",
      "[10,  6400] loss: 0.036\n",
      "[10,  6500] loss: 0.040\n",
      "[10,  6600] loss: 0.029\n",
      "[10,  6700] loss: 0.029\n",
      "[10,  6800] loss: 0.031\n",
      "[10,  6900] loss: 0.031\n",
      "[10,  7000] loss: 0.034\n",
      "[10,  7100] loss: 0.038\n",
      "[10,  7200] loss: 0.044\n",
      "[10,  7300] loss: 0.039\n",
      "[10,  7400] loss: 0.030\n",
      "[10,  7500] loss: 0.064\n",
      "[10,  7600] loss: 0.260\n",
      "[10,  7700] loss: 0.029\n",
      "[10,  7800] loss: 0.028\n",
      "[10,  7900] loss: 0.026\n",
      "[10,  8000] loss: 0.045\n",
      "[10,  8100] loss: 0.034\n",
      "[10,  8200] loss: 0.037\n",
      "[10,  8300] loss: 0.027\n",
      "[10,  8400] loss: 0.033\n",
      "[10,  8500] loss: 0.039\n",
      "[10,  8600] loss: 0.023\n",
      "[10,  8700] loss: 0.030\n",
      "[10,  8800] loss: 0.036\n",
      "[10,  8900] loss: 0.028\n",
      "[10,  9000] loss: 0.028\n",
      "[10,  9100] loss: 0.069\n",
      "[10,  9200] loss: 0.038\n",
      "[10,  9300] loss: 0.044\n",
      "[10,  9400] loss: 0.038\n",
      "[10,  9500] loss: 0.027\n",
      "[10,  9600] loss: 0.041\n",
      "[10,  9700] loss: 0.058\n",
      "[10,  9800] loss: 0.032\n",
      "[10,  9900] loss: 0.028\n",
      "[10, 10000] loss: 0.031\n",
      "[10, 10100] loss: 0.035\n",
      "[10, 10200] loss: 0.030\n",
      "[10, 10300] loss: 0.035\n",
      "[10, 10400] loss: 0.046\n",
      "[10, 10500] loss: 0.033\n",
      "[10, 10600] loss: 0.214\n",
      "[10, 10700] loss: 0.055\n",
      "[10, 10800] loss: 0.028\n",
      "[10, 10900] loss: 0.032\n",
      "[10, 11000] loss: 0.030\n",
      "[10, 11100] loss: 0.031\n",
      "[10, 11200] loss: 0.024\n",
      "[10, 11300] loss: 0.032\n",
      "[10, 11400] loss: 0.035\n",
      "[10, 11500] loss: 0.031\n",
      "[10, 11600] loss: 0.044\n",
      "[10, 11700] loss: 0.032\n",
      "[10, 11800] loss: 0.029\n",
      "[10, 11900] loss: 0.070\n",
      "[10, 12000] loss: 0.391\n",
      "[10, 12100] loss: 0.078\n",
      "[10, 12200] loss: 0.065\n",
      "[10, 12300] loss: 0.258\n",
      "[10, 12400] loss: 0.064\n",
      "[10, 12500] loss: 0.070\n",
      "[10, 12600] loss: 0.065\n",
      "Epoch 10 evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9917    0.9988    0.9953   3055493\n",
      "         1.0     0.9782    0.8626    0.9168    185421\n",
      "\n",
      "    accuracy                         0.9910   3240914\n",
      "   macro avg     0.9850    0.9307    0.9560   3240914\n",
      "weighted avg     0.9909    0.9910    0.9908   3240914\n",
      "\n",
      "AUC: 0.9764\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========== Step 1: 读取 CSV 文件 ==========\n",
    "cols = [\n",
    "    'DCN', 'TRANDATE', 'SEQNUM', 'PERSONID', 'OWNER', 'ROLECODE1', 'ROLECODE2', 'ROLECODE3', 'ROLECODE4',\n",
    "    'ADDRESS1', 'ADDRESS2', 'CITY', 'STATE', 'ZIPCODE', 'COUNTRY', 'PHONE', 'CNAME', 'CNUM',\n",
    "    'CUSIP6', 'CUSIP2', 'TICKER', 'SECID', 'SECTOR', 'INDUSTRY', 'FORMTYPE', 'ACQDISP', 'OPTIONSELL',\n",
    "    'OWNERSHIP', 'SHARESHELD', 'SHARESHELD_ADJ', 'SHARES', 'SHARES_ADJ', 'TPRICE', 'TPRICE_ADJ',\n",
    "    'TRANCODE', 'SECTITLE', 'AMEND', 'CLEANSE', 'FDATE', 'CDATE', 'MAINTDATE', 'SECDATE', 'SIGDATE',\n",
    "    'TRANDATE_AR', 'ACQDISP_AR', 'TPRICE_AR', 'TRANCODE_AR', 'gap_days', 'SEC_Business_Day',\n",
    "    'SEC_Business_Day_Lag2', 'delay', 'id'\n",
    "]\n",
    "\n",
    "# 设置字段类型\n",
    "category_cols = [\n",
    "    'ROLECODE1', 'ROLECODE2', 'ROLECODE3', 'ROLECODE4', 'ACQDISP', 'OPTIONSELL', 'OWNERSHIP',\n",
    "    'TRANCODE', 'SECTITLE', 'FORMTYPE', 'TICKER', 'STATE', 'COUNTRY', 'TRANCODE_AR', 'ACQDISP_AR'\n",
    "]\n",
    "date_cols = [\n",
    "    'TRANDATE', 'FDATE', 'CDATE', 'MAINTDATE', 'SECDATE', 'SIGDATE',\n",
    "    'TRANDATE_AR', 'SEC_Business_Day', 'SEC_Business_Day_Lag2'\n",
    "]\n",
    "numeric_cols = [\n",
    "    'SEQNUM', 'SHARESHELD', 'SHARESHELD_ADJ', 'SHARES', 'SHARES_ADJ',\n",
    "    'TPRICE', 'TPRICE_ADJ', 'gap_days', 'delay'\n",
    "]\n",
    "\n",
    "dtype_dict = {col: 'category' for col in category_cols}\n",
    "dtype_dict.update({col: 'float32' for col in numeric_cols})\n",
    "dtype_dict.update({'id': 'int8'})  # 标签\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"identify_delay.csv\",\n",
    "    usecols=cols,\n",
    "    dtype=dtype_dict,\n",
    "    parse_dates=date_cols,\n",
    "    encoding='ISO-8859-1',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# ========== Step 2: 类别特征编码 ==========\n",
    "for col in category_cols:\n",
    "    df[col] = df[col].astype('str').fillna('missing')\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# ========== Step 3: 日期特征处理 ==========\n",
    "for col in date_cols:\n",
    "    df[f\"{col}_year\"] = df[col].dt.year\n",
    "    df[f\"{col}_month\"] = df[col].dt.month\n",
    "    df[f\"{col}_day\"] = df[col].dt.day\n",
    "    df[f\"{col}_weekday\"] = df[col].dt.weekday\n",
    "    df.drop(columns=col, inplace=True)\n",
    "\n",
    "# ========== Step 4: 删除无用字段 ==========\n",
    "df = df.drop(columns=[\n",
    "    'DCN', 'PERSONID', 'OWNER', 'ADDRESS1', 'ADDRESS2', 'CITY', 'ZIPCODE', 'PHONE', 'CNAME', 'CNUM',\n",
    "    'CUSIP6', 'CUSIP2', 'SECID', 'SECTOR', 'INDUSTRY', 'AMEND', 'CLEANSE'\n",
    "])\n",
    "\n",
    "# ========== Step 5: 处理缺失值 ==========\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# ========== Step 6: 数值特征标准化 ==========\n",
    "scaler = StandardScaler()\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# ========== Step 7: 准备特征和标签 ==========\n",
    "X = df.drop(columns=['id']).values.astype(np.float32)\n",
    "y = df['id'].values.astype(np.float32)\n",
    "\n",
    "# ========== Step 8: 构建 PyTorch 数据集和数据加载器 ==========\n",
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X)\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "train_ds = TabularDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "\n",
    "# ========== Step 9: 定义注意力机制的神经网络 ==========\n",
    "class AttentionNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.attn = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        attn_weights = torch.sigmoid(self.attn(h))\n",
    "        h_attn = h * attn_weights\n",
    "        out = self.fc2(h_attn).squeeze(1)\n",
    "        return h_attn, torch.sigmoid(out)\n",
    "\n",
    "# ========== Step 10: 训练注意力模型并提取特征 ==========\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = AttentionNet(input_dim=X.shape[1]).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 训练模型\n",
    "model.train()\n",
    "for epoch in range(10):  # 训练10个epoch\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _, outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # 每100个小批量打印一次损失值\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\"\"\"\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "model.train()\n",
    "# 假设 train_loader 是您的训练数据加载器\n",
    "for epoch in range(10):  # 训练10个epoch\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_probs = []\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        _, outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # 收集所有标签和预测结果\n",
    "        probs = outputs.detach().cpu().numpy()\n",
    "        predictions = (probs > 0.5).astype(int)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predictions)\n",
    "        all_probs.extend(probs)\n",
    "        \n",
    "        if i % 100 == 99:    # 每100个小批量打印一次损失值\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 计算并打印本 epoch 的评估指标\n",
    "    print(f\"Epoch {epoch + 1} evaluation:\")\n",
    "    print(classification_report(all_labels, all_predictions, digits=4))\n",
    "    auc_score = roc_auc_score(all_labels, all_probs)\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xgb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
